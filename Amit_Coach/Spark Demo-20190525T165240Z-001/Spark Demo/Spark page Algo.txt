val iters = 10
val lines = sc.textFile("G:\\Big_Data\\Simplilearn\\Spark Essentials\\Spark Demo\\PageRankData.txt")
val links = lines.map( s => s.split("\\s+")).map(fields => (fields(0), fields(1))).distinct().groupByKey().cache()
var ranks = links.mapValues(v => 1.0)

for (i <- 1 to iters) {
      val contribs = links.join(ranks).values.flatMap{ case (urls, rank) =>
        val size = urls.size
        urls.map(url => (url, rank / size))
      }
      ranks = contribs.reduceByKey(_ + _).mapValues(0.15 + 0.85 * _)
}

val output = ranks.collect()
output.foreach(tup => println(tup._1 + " has rank: " + tup._2 + "."))